
<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>1. Quickstart: Amortized Posterior Estimation &#8212; BayesFlow: Amortized Bayesian Inference</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  <!--
    this give us a css class that will be invisible only if js is disabled
  -->
  <noscript>
    <style>
      .pst-js-only { display: none !important; }

    </style>
  </noscript>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=a746c00c" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/sphinx-book-theme.css?v=a3416100" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="../_static/custom.css?v=8fec244e" />
  
  <!-- So that users can add custom icons -->
  <script src="../_static/scripts/fontawesome.js?digest=8878045cc6db502f8baf"></script>
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf" />

    <script src="../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../_static/doctools.js?v=9bcbadda"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script src="../_static/design-tabs.js?v=f930bc37"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = '_examples/Intro_Amortized_Posterior_Estimation';</script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <link rel="canonical" href="https://www.bayesflow.org/_examples/Intro_Amortized_Posterior_Estimation.html" />
    <link rel="icon" href="../_static/bayesflow_hex.ico"/>
    <link rel="author" title="About these documents" href="../about.html" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="2. Two Moons: Tackling Bimodal Posteriors" href="TwoMoons_Bimodal_Posterior.html" />
    <link rel="prev" title="Examples" href="../examples.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  <meta name="docsearch:version" content="" />
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <dialog id="pst-search-dialog">
    
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </dialog>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <dialog id="pst-primary-sidebar-modal"></dialog>
      <div id="pst-primary-sidebar" class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../index.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../_static/bayesflow_hex.png" class="logo__image only-light" alt="BayesFlow: Amortized Bayesian Inference - Home"/>
    <img src="../_static/bayesflow_hex.png" class="logo__image only-dark pst-js-only" alt="BayesFlow: Amortized Bayesian Inference - Home"/>
  
  
</a></div>
        <div class="sidebar-primary-item">

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../index.html">BayesFlow</a></li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="../examples.html">Examples</a><details open="open"><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul class="current">
<li class="toctree-l2 current active"><a class="current reference internal" href="#">1. Quickstart: Amortized Posterior Estimation</a></li>
<li class="toctree-l2"><a class="reference internal" href="TwoMoons_Bimodal_Posterior.html">2. Two Moons: Tackling Bimodal Posteriors</a></li>
<li class="toctree-l2"><a class="reference internal" href="Model_Misspecification.html">3. Detecting Model Misspecification in Amortized Posterior Inference</a></li>
<li class="toctree-l2"><a class="reference internal" href="LCA_Model_Posterior_Estimation.html">4. Principled Amortized Bayesian Workflow for Cognitive Modeling</a></li>
<li class="toctree-l2"><a class="reference internal" href="Linear_ODE_system.html">5. Posterior Estimation for ODEs</a></li>
<li class="toctree-l2"><a class="reference internal" href="Covid19_Initial_Posterior_Estimation.html">6. Posterior Estimation for SIR-like Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="Model_Comparison_MPT.html">7. Model Comparison for Cognitive Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="Hierarchical_Model_Comparison_MPT.html">8. Hierarchical Model Comparison for Cognitive Models</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../api/bayesflow.html">Public API: bayesflow package</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../api/bayesflow.benchmarks.html">bayesflow.benchmarks package</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../api/bayesflow.benchmarks.bernoulli_glm.html">bayesflow.benchmarks.bernoulli_glm module</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/bayesflow.benchmarks.bernoulli_glm_raw.html">bayesflow.benchmarks.bernoulli_glm_raw module</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/bayesflow.benchmarks.gaussian_linear.html">bayesflow.benchmarks.gaussian_linear module</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/bayesflow.benchmarks.gaussian_linear_uniform.html">bayesflow.benchmarks.gaussian_linear_uniform module</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/bayesflow.benchmarks.gaussian_mixture.html">bayesflow.benchmarks.gaussian_mixture module</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/bayesflow.benchmarks.inverse_kinematics.html">bayesflow.benchmarks.inverse_kinematics module</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/bayesflow.benchmarks.lotka_volterra.html">bayesflow.benchmarks.lotka_volterra module</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/bayesflow.benchmarks.sir.html">bayesflow.benchmarks.sir module</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/bayesflow.benchmarks.slcp.html">bayesflow.benchmarks.slcp module</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/bayesflow.benchmarks.slcp_distractors.html">bayesflow.benchmarks.slcp_distractors module</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api/bayesflow.benchmarks.two_moons.html">bayesflow.benchmarks.two_moons module</a></li>
</ul>
</details></li>
<li class="toctree-l2"><a class="reference internal" href="../api/bayesflow.amortizers.html">bayesflow.amortizers module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/bayesflow.attention.html">bayesflow.attention module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/bayesflow.coupling_networks.html">bayesflow.coupling_networks module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/bayesflow.diagnostics.html">bayesflow.diagnostics module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/bayesflow.inference_networks.html">bayesflow.inference_networks module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/bayesflow.losses.html">bayesflow.losses module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/bayesflow.networks.html">bayesflow.networks module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/bayesflow.sensitivity.html">bayesflow.sensitivity module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/bayesflow.simulation.html">bayesflow.simulation module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/bayesflow.summary_networks.html">bayesflow.summary_networks module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/bayesflow.trainers.html">bayesflow.trainers module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/bayesflow.configuration.html">bayesflow.configuration module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/bayesflow.default_settings.html">bayesflow.default_settings module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/bayesflow.computational_utilities.html">bayesflow.computational_utilities module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/bayesflow.helper_classes.html">bayesflow.helper_classes module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/bayesflow.helper_functions.html">bayesflow.helper_functions module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/bayesflow.helper_networks.html">bayesflow.helper_networks module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/bayesflow.exceptions.html">bayesflow.exceptions module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/bayesflow.mcmc.html">bayesflow.mcmc module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/bayesflow.version.html">bayesflow.version module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/bayesflow.wrappers.html">bayesflow.wrappers module</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../api/bayesflow.experimental.html">bayesflow.experimental package</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../api/bayesflow.experimental.rectifiers.html">bayesflow.experimental.rectifiers module</a></li>
</ul>
</details></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../installation.html">Full Installation Instructions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../about.html">About us</a></li>
</ul>

    </div>
</nav></div>
        <div class="sidebar-primary-item">
<div class="rst-versions">
   
  <p class="caption" aria-level="2" role="heading"><span class="caption-text">Tags</span></p>
  <ul>
      <li><a href="/v1.1.6/index.html" >v1.1.6</a></li>
      <li><a href="/v1.1.5/index.html" >v1.1.5</a></li>
      <li><a href="/v1.1.4/index.html" >v1.1.4</a></li>
      <li><a href="/v1.1.3/index.html" >v1.1.3</a></li>
      <li><a href="/v1.1.2/index.html" >v1.1.2</a></li>
  </ul>
  
   
  <p class="caption" aria-level="2" role="heading"><span class="caption-text">Branches</span></p>
  <ul>
      <li><a href="/master/index.html" class="current">master</a></li>
  </ul>
  
</div>
</div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
      <div class="sidebar-primary-item">
<div id="ethical-ad-placement"
      class="flat"
      data-ea-publisher="readthedocs"
      data-ea-type="readthedocs-sidebar"
      data-ea-manual="true">
</div></div>
  </div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/bayesflow-org/bayesflow" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/bayesflow-org/bayesflow/edit/master/_examples/Intro_Amortized_Posterior_Estimation.ipynb" target="_blank"
   class="btn btn-sm btn-source-edit-button dropdown-item"
   title="Suggest edit"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-pencil-alt"></i>
  </span>
<span class="btn__text-container">Suggest edit</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/bayesflow-org/bayesflow/issues/new?title=Issue%20on%20page%20%2F_examples/Intro_Amortized_Posterior_Estimation.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/_examples/Intro_Amortized_Posterior_Estimation.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button>


<button class="btn btn-sm pst-navbar-icon search-button search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
</button>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Quickstart: Amortized Posterior Estimation</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#table-of-contents">1.1. Table of Contents</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#introduction">1.2. Introduction <a class="anchor" id="introduction"></a></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#defining-the-generative-model">1.3. Defining the Generative Model <a class="anchor" id="defining_the_generative"></a></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#prior">1.3.1. Prior <a class="anchor" id="prior"></a></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#simulator">1.3.2. Simulator <a class="anchor" id="simulator"></a></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#generative-model">1.3.3. Generative Model <a class="anchor" id="generative_model"></a></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#defining-the-neural-approximator">1.4. Defining the Neural Approximator <a class="anchor" id="defining_the_neural"></a></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#summary-network">1.4.1. Summary Network <a class="anchor" id="summary_network"></a></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#inference-network">1.4.2. Inference Network <a class="anchor" id="inference_network"></a></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#amortized-posterior">1.4.3. Amortized Posterior <a class="anchor" id="amortized_posterior"></a></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#defining-the-trainer">1.5. Defining the Trainer <a class="anchor" id="defining_the_trainer"></a></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#training-phase">1.6. Training Phase <a class="anchor" id="training_phase"></a></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#online-training">1.6.1. Online Training <a class="anchor" id="online_training"></a></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#inspecting-the-loss">1.6.2. Inspecting the Loss <a class="anchor" id="inspecting_the_loss"></a></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#validating-consistency">1.6.3. Validating Consistency <a class="anchor" id="validating_consistency"></a></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#latent-space-inspection">1.6.3.1. Latent space inspection <a class="anchor" id="latent_space_inspection"></a></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#simulation-based-calibration">1.6.3.2. Simulation-Based Calibration <a class="anchor" id="simulation_based_calibration"></a></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#posterior-z-score-and-contraction">1.6.3.3. Posterior z-score and contraction <a class="anchor" id="posterior_z_score_and"></a></a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#inference-phase">1.7. Inference Phase <a class="anchor" id="inference_phase"></a></a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="quickstart-amortized-posterior-estimation">
<h1><span class="section-number">1. </span>Quickstart: Amortized Posterior Estimation<a class="headerlink" href="#quickstart-amortized-posterior-estimation" title="Link to this heading">#</a></h1>
<section id="table-of-contents">
<h2><span class="section-number">1.1. </span>Table of Contents<a class="headerlink" href="#table-of-contents" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p><a class="reference internal" href="#introduction"><span class="xref myst">Introduction</span></a></p></li>
<li><p><a class="reference internal" href="#defining_the_generative"><span class="xref myst">Defining the Generative Model</span></a></p>
<ul>
<li><p><a class="reference internal" href="../api/bayesflow.benchmarks.bernoulli_glm.html#bayesflow.benchmarks.bernoulli_glm.prior" title="bayesflow.benchmarks.bernoulli_glm.prior"><span class="xref myst py py-func">Prior</span></a></p></li>
<li><p><a class="reference internal" href="../api/bayesflow.benchmarks.bernoulli_glm.html#bayesflow.benchmarks.bernoulli_glm.simulator" title="bayesflow.benchmarks.bernoulli_glm.simulator"><span class="xref myst py py-func">Simulator</span></a></p></li>
<li><p><a class="reference internal" href="#generative_model"><span class="xref myst">Generative Model</span></a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#defining_the_neural"><span class="xref myst">Defining the Neural Approximator</span></a></p>
<ul>
<li><p><a class="reference internal" href="#summary_network"><span class="xref myst">Summary Network</span></a></p></li>
<li><p><a class="reference internal" href="#inference_network"><span class="xref myst">Inference Network</span></a></p></li>
<li><p><a class="reference internal" href="#amortized_posterior"><span class="xref myst">Amortized Posterior</span></a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#defining_the_trainer"><span class="xref myst">Defining the Trainer</span></a></p></li>
<li><p><a class="reference internal" href="#training_phase"><span class="xref myst">Training Phase</span></a></p>
<ul>
<li><p><a class="reference internal" href="#online_training"><span class="xref myst">Online Training</span></a></p></li>
<li><p><a class="reference internal" href="#inspecting_the_loss"><span class="xref myst">Inspecting the Loss</span></a></p></li>
<li><p><a class="reference internal" href="#validating_consistency"><span class="xref myst">Validating Consistency</span></a></p>
<ul>
<li><p><a class="reference internal" href="#latent_space_inspection"><span class="xref myst">Latent space inspection</span></a></p></li>
<li><p><a class="reference internal" href="#simulation_based_calibration"><span class="xref myst">Simulation-Based Calibration</span></a></p></li>
<li><p><a class="reference internal" href="#posterior_z_score_and"><span class="xref myst">Posterior z-score and contraction</span></a></p></li>
</ul>
</li>
</ul>
</li>
<li><p><a class="reference internal" href="#inference_phase"><span class="xref myst">Inference Phase</span></a></p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="kn">import</span> <span class="nn">bayesflow</span> <span class="k">as</span> <span class="nn">bf</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2024-02-05 03:05:37.850165: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.
2024-02-05 03:05:38.303673: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2024-02-05 03:05:38.304006: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2024-02-05 03:05:38.402257: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2024-02-05 03:05:38.559381: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.
2024-02-05 03:05:38.563812: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-02-05 03:05:41.393576: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/home/pritom/miniconda3/envs/bayesflow/lib/python3.10/site-packages/bayesflow/trainers.py:27: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html
  from tqdm.autonotebook import tqdm
</pre></div>
</div>
</div>
</div>
</section>
<section id="introduction">
<h2><span class="section-number">1.2. </span>Introduction <a class="anchor" id="introduction"></a><a class="headerlink" href="#introduction" title="Link to this heading">#</a></h2>
<p>Welcome to the very first tutorial on using <strong>BayesFlow</strong> for amortized posterior estimation! In this notebook, we will estimate the means of a multivariate Gaussian model and illustrate some features of the library along the way.</p>
<p>Here is a brief description of amortized posterior estimation:</p>
<p>In traditional posterior estimation, as in Bayesian inference, we seek to compute or approximate the posterior distribution of model parameters given observed data for each new data instance separately. This process can be computationally expensive, especially for complex models or large datasets, because it often involves iterative optimization or sampling methods. This step needs to be repeated for each new instance of data.</p>
<p>Amortized posterior estimation offers a solution to this problem. “Amortization” here refers to spreading out the computational cost over multiple instances. Instead of computing a new posterior from scratch for each data instance, amortized inference learns a function. This function is parameterized by a neural network, that directly maps observations to an approximation of the posterior distribution. This function is trained over the dataset to approximate the posterior for any new data instance efficiently. In this example, we will use a simple Gaussian model to illustrate the basic concepts of amortized posterior estimation.</p>
<p>Above, we have already imported the core entities that we will need for this notebook. In brief:</p>
<ul class="simple">
<li><p>The module <code class="docutils literal notranslate"><span class="pre">simulation</span></code> contains high-level wrappers for gluing together priors, simulators, and context generators into a single <code class="docutils literal notranslate"><span class="pre">GenerativeModel</span></code> object, which will generate all quantities of interest for a modeling scenario.</p></li>
<li><p>The module <code class="docutils literal notranslate"><span class="pre">networks</span></code> contains the core neural architectures used for various tasks, e.g., an <code class="docutils literal notranslate"><span class="pre">InvariantNetwork</span></code> for realizing normalizing flows (https://paperswithcode.com/method/normalizing-flows) or a <code class="docutils literal notranslate"><span class="pre">DeepSet</span></code> for learning permutation-invariant summary representations (embeddings).</p></li>
<li><p>The module <code class="docutils literal notranslate"><span class="pre">amortizers</span></code> contains high-level wrappers which connect the various networks together and instruct them about their particular goals in the inference pipeline.</p></li>
<li><p>The module <code class="docutils literal notranslate"><span class="pre">trainers</span></code> contains high-level wrappers for dictating the <em>training phase</em> of an amortized posterior. Typically, the standard <code class="docutils literal notranslate"><span class="pre">Trainer</span></code> will take care of most scenarios.</p></li>
</ul>
<p>The nuts and bolts of using BayesFlow for Bayesian parameter estimation have already been described in the corresponding papers:</p>
<ul class="simple">
<li><p>Radev, S. T., Mertens, U. K., Voss, A., Ardizzone, L., Köthe, U. (2020). BayesFlow: Learning complex stochastic models with invertible neural networks. <em>IEEE Transactions on Neural Networks and Learning Systems, 33(4)</em>, 1452-1466.</p></li>
<li><p>Radev, S. T., Graw, F., Chen, S., Mutters, N. T., Eichel, V. M., Bärnighausen, T., &amp; Köthe, U. (2021).
OutbreakFlow: Model-based Bayesian inference of disease outbreak dynamics with invertible neural networks and its application to the COVID-19 pandemics in Germany. <em>PLoS computational biology, 17(10)</em>, e1009472.</p></li>
<li><p>Schmitt, M., Bürkner, P. C., Köthe, U., &amp; Radev, S. T. (2021). Detecting model misspecification in amortized Bayesian inference with neural networks. <em>arXiv preprint arXiv:2112.08866</em>.</p></li>
</ul>
<p>At a high level, our architecture consists of a summary network <span class="math notranslate nohighlight">\(h\)</span> and an inference network <span class="math notranslate nohighlight">\(f\)</span> which jointly amortize a generative model.
The summary network transforms input data <span class="math notranslate nohighlight">\(\boldsymbol{x}\)</span> of potentially variable size to a fixed-length representations.
The inference network generates random draws from an approximate posterior <span class="math notranslate nohighlight">\(q\)</span> via a conditional invertible neural network (cINN).
This process is illustrated in the figure below:</p>
<a class="reference internal image-reference" href="../_images/bayesflow_overview.png"><img alt="../_images/bayesflow_overview.png" src="../_images/bayesflow_overview.png" style="width: 90%;" />
</a>
<p>The left panel illustrates the <em>training phase</em>. During this phase, only the model (i.e., simulator and prior) is used to jointly train the summary and inference networks. A parameter vector <span class="math notranslate nohighlight">\(\theta\)</span> is sampled from the prior distribution and then fed to the simulator. The simulator returns <span class="math notranslate nohighlight">\(N\)</span> counts of <span class="math notranslate nohighlight">\(x\)</span> vectors that serve as input to the summary network. The right panel illustrates the <em>inference phase</em>. During this phase, arbitrarily many actually observed data sets can be fed through the networks to obtain posteriors.
For instance, in one recent paper (https://www.nature.com/articles/s41562-021-01282-7), the authors applied pre-trained networks to more than one million observed data sets! Now let’s get into some coding…</p>
<p>First and foremost, we set a local seed for reproducibility (best <code class="docutils literal notranslate"><span class="pre">numpy</span></code> practice as of 2022). See (https://numpy.org/neps/nep-0019-rng-policy.html) for more details.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">RNG</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">(</span><span class="mi">2023</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="defining-the-generative-model">
<h2><span class="section-number">1.3. </span>Defining the Generative Model <a class="anchor" id="defining_the_generative"></a><a class="headerlink" href="#defining-the-generative-model" title="Link to this heading">#</a></h2>
<p>From the perspective of the BayesFlow framework, a generative model is more than just a prior (encoding beliefs about the parameters before observing data) and a simulator (a likelihood function, often implicit, that generates data given parameters). In addition, it consists of various <em>implicit</em> context assumptions, which we can make <em>explicit</em> at any time. Furthermore, we can also <em>amortize</em> over these context variables, thus making our real-world inference more flexible (i.e., applicable to more contexts). We are leveraging the concept of amortized inference and extending it to context variables as well. The figure below illustrates the skeleton of a generative model as conceptualized in the BayesFlow framework.</p>
<a class="reference internal image-reference" href="../_images/generative_model.png"><img alt="../_images/generative_model.png" src="../_images/generative_model.png" style="width: 75%;" />
</a>
<p>This conceptual model allows you to tackle very flexible model families with BayesFlow, as well as various other Bayesian tasks, such as prior sensitivity analysis or multiverse analysis.</p>
<p>Prior sensitivity analysis: it is a technique used in Bayesian statistics to assess how sensitive the results of a model are to the choice of the prior distribution. In Bayesian inference, the prior represents our existing knowledge or assumptions about the parameters before observing the data. However, the selection of an appropriate prior can sometimes be subjective, and different priors can lead to different posterior estimates. Prior sensitivity analysis involves systematically varying the priors and examining how these variations affect the posterior estimates.</p>
<p>The toy Gaussian model we will use for this tutorial takes a particularly simple form:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align}
 \boldsymbol{\mu} &amp;\sim \mathcal{N}_D(\boldsymbol{0}, \sigma_0\mathbb{I}) \\
 \boldsymbol{x}_n &amp;\sim \mathcal{N}_D(\boldsymbol{\mu}, \sigma_1\mathbb{I})\quad\textrm{ for } n = 1,..,N,
\end{align}
\end{split}\]</div>
<p>where <span class="math notranslate nohighlight">\(\mathcal{N}_D\)</span> denotes a multivariate Gaussian (normal) density with <span class="math notranslate nohighlight">\(D\)</span> dimensions, which we set at <span class="math notranslate nohighlight">\(D = 4\)</span> for the current example. For simplicity, we will also set <span class="math notranslate nohighlight">\(\sigma_0 =1\)</span> and <span class="math notranslate nohighlight">\(\sigma_1 = 1\)</span>. We will now implement this model using the latest numpy interface.</p>
<section id="prior">
<h3><span class="section-number">1.3.1. </span>Prior <a class="anchor" id="prior"></a><a class="headerlink" href="#prior" title="Link to this heading">#</a></h3>
<p>We first define a function generating single draws from the prior (as specified by our model formulation above), which we pass to the <code class="docutils literal notranslate"><span class="pre">Prior</span></code> wrapper.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">prior_fun</span><span class="p">(</span><span class="n">D</span><span class="o">=</span><span class="mi">4</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">RNG</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="n">D</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">prior</span> <span class="o">=</span> <span class="n">bf</span><span class="o">.</span><span class="n">simulation</span><span class="o">.</span><span class="n">Prior</span><span class="p">(</span><span class="n">prior_fun</span><span class="o">=</span><span class="n">prior_fun</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>That’s it. The <code class="docutils literal notranslate"><span class="pre">Prior</span></code> object is now callable with a <code class="docutils literal notranslate"><span class="pre">batch_size</span></code> argument which dictates how many draws are generated from the prior. We can take a look at the outputs of the prior by doing:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">prior</span><span class="p">(</span><span class="n">batch_size</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>{&#39;prior_draws&#39;: array([[ 0.60172129,  1.15161897, -1.35946236,  0.22205533],
        [-0.77586755,  0.8087058 , -0.19862826, -1.57869386],
        [-0.6292893 , -0.38775694,  0.05018619, -0.90704364],
        [ 0.13213809,  1.40490249,  0.40410205, -1.03741343],
        [-0.74180264,  1.26349944, -0.68932403,  0.70801477],
        [-0.03504752, -0.83781649, -0.73251795,  1.04738251],
        [-1.4238012 ,  1.35404102, -0.39509257, -0.92921568],
        [ 0.44406269,  0.14221762,  1.36874071, -0.49876242],
        [-0.0742687 ,  0.93937197, -0.62614275, -1.02895874],
        [-2.13303915,  0.90438789, -2.08440387,  0.28253568]]),
 &#39;batchable_context&#39;: None,
 &#39;non_batchable_context&#39;: None}
</pre></div>
</div>
</div>
</div>
<p>Wow! The prior generated some other stuff that we never specified and packed it into a Python <code class="docutils literal notranslate"><span class="pre">dict</span></code>. That definitely needs some explanation. Remember our picture above? A prior can also accept context variables which modify its behavior, whenever this is desirable. We will see this when we illustrate how to perform <em>prior sensitivity</em> analysis.
We also see two types of context variables. These are worth mentioning as well.
The interface distinguishes between two types of context: <code class="docutils literal notranslate"><span class="pre">batchable_context</span></code> and <code class="docutils literal notranslate"><span class="pre">non_batchable_context</span></code>. This distinction is a purely technical, rather then a conceptual one:</p>
<ul class="simple">
<li><p>Batchable context variables differ for each simulation in each training batch of simulations;</p></li>
<li><p>Non-batchable context variables stay the same for each simulation in a batch, but differ across simulated batches;</p></li>
</ul>
<p>Examples for <strong>batchable</strong> context variables include experimental design variables, design matrices, etc.
Examples for <strong>non-batchable</strong> context variables include the number of observations in an experiment, positional encodings, time indices, etc. While the latter can also be considered batchable in principle, batching them would require non-Tensor (i.e., non-rectangular) data structures. When you have a variable that changes its structure or size across different batches (like varying the number of observations), it doesn’t fit neatly into a rectangular tensor structure. One would need to use non-tensor data structures, which are not as efficiently processed by the hardware typically used for machine learning computations (like GPUs).</p>
</section>
<section id="simulator">
<h3><span class="section-number">1.3.2. </span>Simulator <a class="anchor" id="simulator"></a><a class="headerlink" href="#simulator" title="Link to this heading">#</a></h3>
<p>In this case, our simulator function is equally simple to our prior function. We will call it a likelihood function, in correspondence with standard Bayesian terminology, and pass it to the <code class="docutils literal notranslate"><span class="pre">Simulator</span></code> wrapper.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">likelihood_fun</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">n_obs</span><span class="o">=</span><span class="mi">50</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">RNG</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="n">params</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">n_obs</span><span class="p">,</span> <span class="n">params</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">simulator</span> <span class="o">=</span> <span class="n">bf</span><span class="o">.</span><span class="n">simulation</span><span class="o">.</span><span class="n">Simulator</span><span class="p">(</span><span class="n">simulator_fun</span><span class="o">=</span><span class="n">likelihood_fun</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Note, that we define our simulator function or <code class="docutils literal notranslate"><span class="pre">likelihood_fun</span></code> with two arguments. A positional argument, <code class="docutils literal notranslate"><span class="pre">params</span></code> which stands for a single random draw from the prior and a keyword argument <code class="docutils literal notranslate"><span class="pre">n_obs</span></code> which represents the number of observations <span class="math notranslate nohighlight">\(N\)</span> that we will generate from the likelihood for each draw from the prior. As some point, we want to vary <span class="math notranslate nohighlight">\(N\)</span> during training, so that the architecture can generalize to different values of <span class="math notranslate nohighlight">\(N\)</span> during inference.</p>
</section>
<section id="generative-model">
<h3><span class="section-number">1.3.3. </span>Generative Model <a class="anchor" id="generative_model"></a><a class="headerlink" href="#generative-model" title="Link to this heading">#</a></h3>
<p>We will now connect the prior with the likelihood (simulator) via the <code class="docutils literal notranslate"><span class="pre">GenerativeModel</span></code> interface:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">bf</span><span class="o">.</span><span class="n">simulation</span><span class="o">.</span><span class="n">GenerativeModel</span><span class="p">(</span><span class="n">prior</span><span class="o">=</span><span class="n">prior</span><span class="p">,</span> <span class="n">simulator</span><span class="o">=</span><span class="n">simulator</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>INFO:root:Performing 2 pilot runs with the anonymous model...
INFO:root:Shape of parameter batch after 2 pilot simulations: (batch_size = 2, 4)
INFO:root:Shape of simulation batch after 2 pilot simulations: (batch_size = 2, 50, 4)
INFO:root:No optional prior non-batchable context provided.
INFO:root:No optional prior batchable context provided.
INFO:root:No optional simulation non-batchable context provided.
INFO:root:No optional simulation batchable context provided.
</pre></div>
</div>
</div>
</div>
<p>The generative model will also provide an internal consistency check and report on the tensor shapes of the different quantities output by the model. We can also manually inspect its outputs for <code class="docutils literal notranslate"><span class="pre">batch_size</span> <span class="pre">=</span> <span class="pre">3</span></code> (i.e., three simulations):</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">out</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">batch_size</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">out</span><span class="o">.</span><span class="n">keys</span><span class="p">()))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[&#39;prior_non_batchable_context&#39;, &#39;prior_batchable_context&#39;, &#39;prior_draws&#39;, &#39;sim_non_batchable_context&#39;, &#39;sim_batchable_context&#39;, &#39;sim_data&#39;]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Shape of sim_data: &quot;</span><span class="p">,</span> <span class="n">out</span><span class="p">[</span><span class="s2">&quot;sim_data&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Shape of sim_data:  (3, 50, 4)
</pre></div>
</div>
</div>
</div>
<p>The output of the <code class="docutils literal notranslate"><span class="pre">GenerativeModel</span></code> is also a Python <code class="docutils literal notranslate"><span class="pre">dict</span></code> with even more keys than before. You should probably have an intuition what these keys represent, namely, the different types of context variables (none in this case) for prior and simulator. With this simple set-up, we can now proceed to do some posterior estimation.</p>
</section>
</section>
<section id="defining-the-neural-approximator">
<h2><span class="section-number">1.4. </span>Defining the Neural Approximator <a class="anchor" id="defining_the_neural"></a><a class="headerlink" href="#defining-the-neural-approximator" title="Link to this heading">#</a></h2>
<section id="summary-network">
<h3><span class="section-number">1.4.1. </span>Summary Network <a class="anchor" id="summary_network"></a><a class="headerlink" href="#summary-network" title="Link to this heading">#</a></h3>
<p>Since our likelihood generates data exchangeably, we need to respect the permutation invariance of the data. Exchangeability in data means that the probability distribution of a sequence of observations remains the same regardless of the order in which the observations appear. In other words, the data is permutation invariant. For that, we will use a <code class="docutils literal notranslate"><span class="pre">DeepSet</span></code> which does exactly that. This network will take (at least) 3D tensors of shape <code class="docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">n_obs,</span> <span class="pre">D)</span></code> and reduce them to 2D tensors of shape <code class="docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">summary_dim)</span></code>, where <code class="docutils literal notranslate"><span class="pre">summary_dim</span></code> is a hyperparameter to be set by the user (you). Heuristically, this number should not be lower than the number of parameters in a model. Below, we create a permutation-invariant network with <code class="docutils literal notranslate"><span class="pre">summary_dim</span> <span class="pre">=</span> <span class="pre">10</span></code>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">summary_net</span> <span class="o">=</span> <span class="n">bf</span><span class="o">.</span><span class="n">networks</span><span class="o">.</span><span class="n">DeepSet</span><span class="p">(</span><span class="n">summary_dim</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Note, that the hyperparameter setting for the <code class="docutils literal notranslate"><span class="pre">InvariantNetwork</span></code> are all provided inside a single Python dictionary. Here, <code class="docutils literal notranslate"><span class="pre">InvariantNetwork</span></code> is used to learn a summary representation of data that is invariant to the permutation of its elements. It helps to inspect the outputs of the summary network manually and confirm its operation:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">test_inp</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">batch_size</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="n">summary_rep</span> <span class="o">=</span> <span class="n">summary_net</span><span class="p">(</span><span class="n">test_inp</span><span class="p">[</span><span class="s2">&quot;sim_data&quot;</span><span class="p">])</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Shape of simulated data sets: &quot;</span><span class="p">,</span> <span class="n">test_inp</span><span class="p">[</span><span class="s2">&quot;sim_data&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Shape of summary vectors: &quot;</span><span class="p">,</span> <span class="n">summary_rep</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Shape of simulated data sets:  (3, 50, 4)
Shape of summary vectors:  (3, 10)
</pre></div>
</div>
</div>
</div>
<p>It is these summary vectors that will enter as conditions for the inference network. Upon convergence of the simulation-based training, we can think of them as <em>learned summary statistics</em> or <em>data embeddings</em>.</p>
</section>
<section id="inference-network">
<h3><span class="section-number">1.4.2. </span>Inference Network <a class="anchor" id="inference_network"></a><a class="headerlink" href="#inference-network" title="Link to this heading">#</a></h3>
<p>Next, we define the main workhorse of our our framework for amortized posterior inference - the conditional invertible neural network (cINN). The only mandatory hyperparameter for the <code class="docutils literal notranslate"><span class="pre">InvertibleNetwork</span></code> is the number of parameters we aim to estimate, in our case <code class="docutils literal notranslate"><span class="pre">num_params</span> <span class="pre">=</span> <span class="pre">4</span></code>. However, we can change some more, for instance set the number of coupling layers <code class="docutils literal notranslate"><span class="pre">num_coupling_layers</span> <span class="pre">=</span> <span class="pre">4</span></code>, which will make training a bit faster than using the default <code class="docutils literal notranslate"><span class="pre">num_coupling_layers</span> <span class="pre">=</span> <span class="pre">6</span></code>, but also reduce the expressiveness (performance) of our network. Naturally, we don’t need a lot of expressiveness for our trivial Gaussian model, so we can proceed with <code class="docutils literal notranslate"><span class="pre">num_coupling_layers</span> <span class="pre">=</span> <span class="pre">4</span></code>.</p>
<p>The invertible inference network has the following further hyperparameters:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">num_params</span></code> (mandatory) - The number of model parameters (eq. the dimensionality of the latent space).</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">num_coupling_layers</span></code> - The number of invertible layers. The more layers, the more powerful the network, but the slower and possibly less stable the training. Typically <span class="math notranslate nohighlight">\(6 - 10\)</span> coupling layers should be sufficient.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">coupling_settings</span></code> - The settings for the internal coupling layers. Typically, the defaults work well. For online training, you should switch off the default regularization as it may prevent optimal performance.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">coupling_design</span></code> - You could try setting the design to <code class="docutils literal notranslate"><span class="pre">spline</span></code> for more superior performance on lower-dimensional problems.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">soft_clamping</span></code> - The soft-clamping parameter. Just use the default value.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">permutation</span></code> - Whether to use permutations before each coupling layer. Should be used by default.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">use_act_norm</span></code> - Whether to apply activation normalization after each coupling layer (https://arxiv.org/abs/1807.03039). Works well in practice and stabilizes training.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">act_norm_init</span></code> - In some cases, you can perform data-dependent initialization of the <code class="docutils literal notranslate"><span class="pre">ActNorm</span></code> layers, as in https://arxiv.org/abs/1807.03039.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">use_soft_flow</span></code> - Whether to use a SoftFlow architecture (https://arxiv.org/abs/2006.04604). Useful for degenerate distributions.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">soft_flow_bounds</span></code> - The bounds for the varying standard deviation of <code class="docutils literal notranslate"><span class="pre">SoftFlow</span></code>’s noise. Do not touch, unless you have good reasons to.</p></li>
</ul>
<p>You can glean all the defaults in the <code class="docutils literal notranslate"><span class="pre">default_settings</span></code> module. For most applications, you only need to define the <code class="docutils literal notranslate"><span class="pre">num_params</span></code> and <code class="docutils literal notranslate"><span class="pre">num_coupling_layers</span></code> hyperparameters.</p>
<p>Note, that we also remove the default <code class="docutils literal notranslate"><span class="pre">L2</span></code> and <code class="docutils literal notranslate"><span class="pre">dropout</span></code> regularization from the networks, as we need this only for offline learning with pre-simulated data. In the context of online learning, where the model is continuously updated with new data, regularization can be counterproductive. It can unnecessarily constrain the model, preventing it from fully adapting to the latest data.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">inference_net</span> <span class="o">=</span> <span class="n">bf</span><span class="o">.</span><span class="n">networks</span><span class="o">.</span><span class="n">InvertibleNetwork</span><span class="p">(</span>
    <span class="n">num_params</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
    <span class="n">num_coupling_layers</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
    <span class="n">coupling_settings</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;dense_args&quot;</span><span class="p">:</span> <span class="nb">dict</span><span class="p">(</span><span class="n">kernel_regularizer</span><span class="o">=</span><span class="kc">None</span><span class="p">),</span> <span class="s2">&quot;dropout&quot;</span><span class="p">:</span> <span class="kc">False</span><span class="p">},</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Again, we can inspect the raw outputs of the cINN by feeding it the parameter draws and corresponding data summaries. This network is slightly more involved than the summary network, as it has two mandatory inputs: <code class="docutils literal notranslate"><span class="pre">targets</span></code> and <code class="docutils literal notranslate"><span class="pre">condition</span></code>. It also has two outputs: <code class="docutils literal notranslate"><span class="pre">z</span></code> and <code class="docutils literal notranslate"><span class="pre">log_det_J</span></code>, which represent the latent representation of the parameters and the log of the Jacobian determinant, respectively.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">z</span><span class="p">,</span> <span class="n">log_det_J</span> <span class="o">=</span> <span class="n">inference_net</span><span class="p">(</span><span class="n">test_inp</span><span class="p">[</span><span class="s2">&quot;prior_draws&quot;</span><span class="p">],</span> <span class="n">summary_rep</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Note about <code class="docutils literal notranslate"><span class="pre">z</span></code>: The inference network takes summary vectors as input and outputs latent vectors (<code class="docutils literal notranslate"><span class="pre">z</span></code>). The latent space is a lower-dimensional space that is assumed to capture the essential information about the parameters. It is essentially transforming the parameter space to the latent space (Gaussian in this case).</p>
<p>We can inspect the shapes of the outputs as well:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Shape of latent variables:&quot;</span><span class="p">,</span> <span class="n">z</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Shape of log det Jacobian:&quot;</span><span class="p">,</span> <span class="n">log_det_J</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Shape of latent variables: (3, 4)
Shape of log det Jacobian: (3,)
</pre></div>
</div>
</div>
</div>
</section>
<section id="amortized-posterior">
<h3><span class="section-number">1.4.3. </span>Amortized Posterior <a class="anchor" id="amortized_posterior"></a><a class="headerlink" href="#amortized-posterior" title="Link to this heading">#</a></h3>
<p>We can now connect the <code class="docutils literal notranslate"><span class="pre">summary_net</span></code> and the <code class="docutils literal notranslate"><span class="pre">inference_net</span></code> via the high-level wrapper <code class="docutils literal notranslate"><span class="pre">AmortizedPosterior</span></code>. This wrapper knows how to compute its loss function, draw samples from the approximate posterior given new data and also compute normalized posterior densities. Normalized posterior density refers to a posterior probability distribution that has been adjusted so that its total area (or volume, in the case of multi-dimensional distributions) sums up to one.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">amortizer</span> <span class="o">=</span> <span class="n">bf</span><span class="o">.</span><span class="n">amortizers</span><span class="o">.</span><span class="n">AmortizedPosterior</span><span class="p">(</span><span class="n">inference_net</span><span class="p">,</span> <span class="n">summary_net</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="defining-the-trainer">
<h2><span class="section-number">1.5. </span>Defining the Trainer <a class="anchor" id="defining_the_trainer"></a><a class="headerlink" href="#defining-the-trainer" title="Link to this heading">#</a></h2>
<p>The <code class="docutils literal notranslate"><span class="pre">Trainer</span></code> instance connects a generative model with an amortizer and enables various types of simulation-based training. Actually, it has only a single mandatory argument, <code class="docutils literal notranslate"><span class="pre">amortizer</span></code>, which expect an <code class="docutils literal notranslate"><span class="pre">Amortized*</span></code> instance. However, in order to be able to perform on-the-fly simulation-based training (see below), we also need to provide the generative model. Note, that the generative model does not need to use our provided wrappers, but the keys of its dictionary output should adhere to BayesFlow’s expectations.</p>
<p>Note: If you want to automatically save the <code class="docutils literal notranslate"><span class="pre">amortizer</span></code> and related loss history, you can provide a <code class="docutils literal notranslate"><span class="pre">checkpoint_path</span></code> argument indicating the folder for storing the checkpoints.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">trainer</span> <span class="o">=</span> <span class="n">bf</span><span class="o">.</span><span class="n">trainers</span><span class="o">.</span><span class="n">Trainer</span><span class="p">(</span><span class="n">amortizer</span><span class="o">=</span><span class="n">amortizer</span><span class="p">,</span> <span class="n">generative_model</span><span class="o">=</span><span class="n">model</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>INFO:root:Performing a consistency check with provided components...
INFO:root:Done.
</pre></div>
</div>
</div>
</div>
<p>Actually, a <code class="docutils literal notranslate"><span class="pre">Trainer</span></code> instance does a little more than connect a generative model to an amortizer. It does so through the help of a <code class="docutils literal notranslate"><span class="pre">configurator</span></code>. In our case the configurator was inferred from the type of amortizer provided, but for more involved models, you should define the configurator explicitly.</p>
<p>What does a configurator do? It takes the raw outputs of the generative models and turns them into something with which neural networks can work:</p>
<a class="reference internal image-reference" href="../_images/trainer_connection.png"><img alt="../_images/trainer_connection.png" src="../_images/trainer_connection.png" style="width: 75%;" />
</a>
<p>Let’s see how this actually works by accessing the default (inferred) configurator from the <code class="docutils literal notranslate"><span class="pre">Trainer</span></code> instance.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Simulate some data again</span>
<span class="n">out</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Keys of simulated dict: &quot;</span><span class="p">,</span> <span class="nb">list</span><span class="p">(</span><span class="n">out</span><span class="o">.</span><span class="n">keys</span><span class="p">()))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Keys of simulated dict:  [&#39;prior_non_batchable_context&#39;, &#39;prior_batchable_context&#39;, &#39;prior_draws&#39;, &#39;sim_non_batchable_context&#39;, &#39;sim_batchable_context&#39;, &#39;sim_data&#39;]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">conf_out</span> <span class="o">=</span> <span class="n">trainer</span><span class="o">.</span><span class="n">configurator</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Keys of configured dict: &quot;</span><span class="p">,</span> <span class="nb">list</span><span class="p">(</span><span class="n">conf_out</span><span class="o">.</span><span class="n">keys</span><span class="p">()))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Keys of configured dict:  [&#39;summary_conditions&#39;, &#39;direct_conditions&#39;, &#39;parameters&#39;]
</pre></div>
</div>
</div>
</div>
<p>The default configurator for posterior inference differentiates between three types of model outputs:</p>
<ol class="arabic simple">
<li><p><code class="docutils literal notranslate"><span class="pre">parameters</span></code> - these are the quantities for which we want posteriors.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">summary_conditions</span></code> - these are the quantities that go through the summary network (typically the raw data).</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">direct_conditions</span></code> – these are concatenated with the outputs of the summary network and passed directly to the inference network.</p></li>
</ol>
<p>In our case, <code class="docutils literal notranslate"><span class="pre">summary_conditions</span></code> simply correspond to the data, and <code class="docutils literal notranslate"><span class="pre">parameters</span></code> correspond to the prior draws, but you can imagine that more complex scenarios are possible. Let’s confirm the former claims.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">out</span><span class="p">[</span><span class="s2">&quot;sim_data&quot;</span><span class="p">],</span> <span class="n">conf_out</span><span class="p">[</span><span class="s2">&quot;summary_conditions&quot;</span><span class="p">]))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">out</span><span class="p">[</span><span class="s2">&quot;prior_draws&quot;</span><span class="p">],</span> <span class="n">conf_out</span><span class="p">[</span><span class="s2">&quot;parameters&quot;</span><span class="p">]))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>True
True
</pre></div>
</div>
</div>
</div>
<p>Here, we are not using direct equality, since the configurator converts <code class="docutils literal notranslate"><span class="pre">float64</span></code> numbers to <code class="docutils literal notranslate"><span class="pre">float32</span></code> so as to use GPU memory more efficiently.</p>
</section>
<section id="training-phase">
<h2><span class="section-number">1.6. </span>Training Phase <a class="anchor" id="training_phase"></a><a class="headerlink" href="#training-phase" title="Link to this heading">#</a></h2>
<p>The following training modes are currently available:</p>
<ul class="simple">
<li><p><strong>Online training</strong> - This training regime is optimal for fast generative models which can efficiently simulate data on-the-fly. In order for this training regime to be efficient, on-the-fly batch simulations should not take longer than 2-3 seconds. The networks never see the same simulations twice, so no regularization (which are primarily used to prevent overfitting on a static dataset) is necessary. This training mode ensures that the model is constantly adapting to fresh data, enhancing its ability to generalize and learn diverse patterns.</p></li>
<li><p><strong>Experience replay</strong> - This training regime is also good for fast generative models which can efficiently simulated data on-the-fly. It will use a memory replay buffer, as utilized in reinforcement learning, so the network will eventually “experience” some simulations multiple times. This allows it to reinforce its learning from these repeated experiences. Experience replay can help improve learning efficiency and stability, especially in scenarios where generating entirely new simulations on-the-fly for every training step may not be optimal.</p></li>
<li><p><strong>Round-based training</strong> - This training regime is optimal for slow, but still reasonably performant generative models. In order for this training regime to be efficient, on-the-fly batch simulations should not take longer than one 2-3 minutes. In round-based training, simulations are generated in rounds, and each round of simulations is used for a phase of training before generating new simulations for the next round. This creates a balance between the need for new data and the computational cost of generating it.</p></li>
<li><p><strong>Offline training</strong> - This training regime is optimal for very slow, external simulators, which take several minutes for a single simulation. It assumes that all training data has already been simulated and stored on disk. Default regularization should be used (or even increase for very small data sets). This method is less flexible but it is used in cases where the generative model is too slow to generate data on-the-fly.</p></li>
</ul>
<p>Usually, domain modelers have a pretty good understanding of how fast a simulation model runs. We can also quickly measure the time taken for a given number of simulations (<code class="docutils literal notranslate"><span class="pre">batch_size</span></code>) directly inside the notebook.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%time</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="mi">32</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>CPU times: user 3.35 ms, sys: 10 µs, total: 3.36 ms
Wall time: 3.67 ms
</pre></div>
</div>
</div>
</div>
<p>We are well below the recommended 2-3 seconds for online training, so that is what we will do. Online training has three mandatory parameters: <code class="docutils literal notranslate"><span class="pre">epochs</span></code>, <code class="docutils literal notranslate"><span class="pre">iterations_per_epoch</span></code>, and <code class="docutils literal notranslate"><span class="pre">batch_size</span></code>. Thus, the total number of simulations that will be performed by a single call (run) will be <code class="docutils literal notranslate"><span class="pre">epochs</span></code> <span class="math notranslate nohighlight">\(\times\)</span> <code class="docutils literal notranslate"><span class="pre">iterations_per_epoch</span></code> <span class="math notranslate nohighlight">\(\times\)</span>  <code class="docutils literal notranslate"><span class="pre">batch_size</span></code>. Moreover, the networks will never experience the same simulation twice, since each batch will contain a new set of simulations.</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">epochs</span></code>: This parameter defines the total number of complete passes through the training dataset. Each epoch consists of several iterations, where the model is exposed to different subsets of the data.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">iterations_per_epoch</span></code>: This specifies the number of training iterations that occur in each epoch. During each iteration, the model is updated based on a batch of new data.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">batch_size</span></code>: This determines the number of simulations in each batch. It’s the size of the data subset that the model will see and learn from in each iteration.</p></li>
</ul>
<section id="online-training">
<h3><span class="section-number">1.6.1. </span>Online Training <a class="anchor" id="online_training"></a><a class="headerlink" href="#online-training" title="Link to this heading">#</a></h3>
<p>Note how the average loss goes down, along with the learning rate (LR). The latter happens, because BayesFlow uses a cosine decay for the learning rate by default, unless a custom optimizer from <code class="docutils literal notranslate"><span class="pre">tensorflow.optimizers</span></code> is provided. Thus, the learning rate will decrease atuomatically from its default value of <span class="math notranslate nohighlight">\(0.0005\)</span> to <span class="math notranslate nohighlight">\(0\)</span> over the course of the training. We will also use <span class="math notranslate nohighlight">\(200\)</span> simulations for tracking validation error (even though we don’t strictly need to do this for online learning, where the network sees a completely new batch of data in each iteration). This step is about assessing the model’s performance on a separate set of data that it hasn’t been trained on. It’s a way to monitor how well the model generalizes to new, unseen data.</p>
<p>Depending on your hardware, this training should take between <span class="math notranslate nohighlight">\(30\)</span> seconds and <span class="math notranslate nohighlight">\(5\)</span> minutes. Note, that for actual applications, we will train considerably longer than <span class="math notranslate nohighlight">\(5\)</span> epochs.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%time</span>
<span class="n">history</span> <span class="o">=</span> <span class="n">trainer</span><span class="o">.</span><span class="n">train_online</span><span class="p">(</span><span class="n">epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">iterations_per_epoch</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">validation_sims</span><span class="o">=</span><span class="mi">200</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>INFO:root:Generated 200 simulations for validation.
Training epoch 1:   0%|          | 0/1000 [00:00&lt;?, ?it/s]
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Training epoch 1: 100%|██████████| 1000/1000 [01:42&lt;00:00,  9.72it/s, Epoch: 1, Iter: 1000,Loss: -0.002,Avg.Loss: 1.520,LR: 4.88E-04]
INFO:root:Validation, Epoch: 1, Loss: -0.310
Training epoch 2: 100%|██████████| 1000/1000 [00:53&lt;00:00, 18.72it/s, Epoch: 2, Iter: 1000,Loss: -1.684,Avg.Loss: -1.179,LR: 4.52E-04]
INFO:root:Validation, Epoch: 2, Loss: -1.507
Training epoch 3: 100%|██████████| 1000/1000 [00:52&lt;00:00, 18.95it/s, Epoch: 3, Iter: 1000,Loss: -2.126,Avg.Loss: -1.550,LR: 3.97E-04]
INFO:root:Validation, Epoch: 3, Loss: -1.887
Training epoch 4: 100%|██████████| 1000/1000 [00:52&lt;00:00, 19.08it/s, Epoch: 4, Iter: 1000,Loss: -1.558,Avg.Loss: -1.746,LR: 3.27E-04]
INFO:root:Validation, Epoch: 4, Loss: -1.805
Training epoch 5: 100%|██████████| 1000/1000 [00:52&lt;00:00, 19.06it/s, Epoch: 5, Iter: 1000,Loss: -1.588,Avg.Loss: -1.856,LR: 2.50E-04]
INFO:root:Validation, Epoch: 5, Loss: -2.132
Training epoch 6: 100%|██████████| 1000/1000 [00:53&lt;00:00, 18.74it/s, Epoch: 6, Iter: 1000,Loss: -1.779,Avg.Loss: -1.938,LR: 1.73E-04]
INFO:root:Validation, Epoch: 6, Loss: -2.102
Training epoch 7: 100%|██████████| 1000/1000 [00:52&lt;00:00, 19.00it/s, Epoch: 7, Iter: 1000,Loss: -2.131,Avg.Loss: -2.011,LR: 1.03E-04]
INFO:root:Validation, Epoch: 7, Loss: -2.171
Training epoch 8: 100%|██████████| 1000/1000 [00:46&lt;00:00, 21.44it/s, Epoch: 8, Iter: 1000,Loss: -2.051,Avg.Loss: -2.069,LR: 4.78E-05]
INFO:root:Validation, Epoch: 8, Loss: -2.229
Training epoch 9: 100%|██████████| 1000/1000 [00:39&lt;00:00, 25.57it/s, Epoch: 9, Iter: 1000,Loss: -2.375,Avg.Loss: -2.123,LR: 1.23E-05]
INFO:root:Validation, Epoch: 9, Loss: -2.249
Training epoch 10: 100%|██████████| 1000/1000 [00:39&lt;00:00, 25.55it/s, Epoch: 10, Iter: 1000,Loss: -2.243,Avg.Loss: -2.145,LR: 1.49E-11]
INFO:root:Validation, Epoch: 10, Loss: -2.274
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>CPU times: user 12min 41s, sys: 44 s, total: 13min 25s
Wall time: 9min 8s
</pre></div>
</div>
</div>
</div>
</section>
<section id="inspecting-the-loss">
<h3><span class="section-number">1.6.2. </span>Inspecting the Loss <a class="anchor" id="inspecting_the_loss"></a><a class="headerlink" href="#inspecting-the-loss" title="Link to this heading">#</a></h3>
<p>Bayesian models can be complex and computationally intensive, and metrics like training and validation loss can provide critical insights into the model’s performance and stability. A decreasing loss over time indicates that the model is learning effectively, while fluctuations or increases in loss might suggest issues in the training process, such as overfitting, underfitting, or inappropriate learning rate settings. We can inspect the evolution of the loss via a utility function <code class="docutils literal notranslate"><span class="pre">plot_losses</span></code>, for which we have imported the <code class="docutils literal notranslate"><span class="pre">diagnostics</span></code> module from <code class="docutils literal notranslate"><span class="pre">BayesFlow</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">f</span> <span class="o">=</span> <span class="n">bf</span><span class="o">.</span><span class="n">diagnostics</span><span class="o">.</span><span class="n">plot_losses</span><span class="p">(</span><span class="n">history</span><span class="p">[</span><span class="s2">&quot;train_losses&quot;</span><span class="p">],</span> <span class="n">history</span><span class="p">[</span><span class="s2">&quot;val_losses&quot;</span><span class="p">],</span> <span class="n">moving_average</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/1ec2fc070cab4ab3f37f27b4afccb99215f5aa083079233c2a1d1e1fb315c258.png" src="../_images/1ec2fc070cab4ab3f37f27b4afccb99215f5aa083079233c2a1d1e1fb315c258.png" />
</div>
</div>
</section>
<section id="validating-consistency">
<h3><span class="section-number">1.6.3. </span>Validating Consistency <a class="anchor" id="validating_consistency"></a><a class="headerlink" href="#validating-consistency" title="Link to this heading">#</a></h3>
<p>Validating the consistency of our model-amortizer coupling is an important step which should be performed before any real data are presented to the networks. In other words, the model should work in the ‘’small world’’, before going out in the world of real data. This involves testing the model under known conditions and ensuring that it behaves logically and accurately. It is a critical step to avoid surprises when the model is later exposed to real and more complex data. In addition to a smooth loss reduction curve, we can use at least four handy diagnostic utilities.</p>
<p>For a better illustration, we will start by generating some test simulations (not seen during training) using the simulator <code class="docutils literal notranslate"><span class="pre">model</span></code>. Note, that we also use the default configurator to prepare these test simulations for interacting with the networks.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">test_sims</span> <span class="o">=</span> <span class="n">trainer</span><span class="o">.</span><span class="n">configurator</span><span class="p">(</span><span class="n">model</span><span class="p">(</span><span class="mi">500</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<section id="latent-space-inspection">
<h4><span class="section-number">1.6.3.1. </span>Latent space inspection <a class="anchor" id="latent_space_inspection"></a><a class="headerlink" href="#latent-space-inspection" title="Link to this heading">#</a></h4>
<p>Since our training objective prescribes a unit Gaussian to the latent variable <span class="math notranslate nohighlight">\(\boldsymbol{z}\)</span> (see: https://arxiv.org/abs/2003.06281), we expect that, upon good convergence, the latent space will exhibit the prescribed probabilistic structure. Good convergence means that the model has learned an appropriate representation of the data in its latent space. We can quickly inspect this structure by calling the <code class="docutils literal notranslate"><span class="pre">plot_latent_space_2d</span></code> function from the <code class="docutils literal notranslate"><span class="pre">diagnostics</span></code> module.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">z_samples</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">amortizer</span><span class="p">(</span><span class="n">test_sims</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">f</span> <span class="o">=</span> <span class="n">bf</span><span class="o">.</span><span class="n">diagnostics</span><span class="o">.</span><span class="n">plot_latent_space_2d</span><span class="p">(</span><span class="n">z_samples</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/4020385795cb3ce7ae1fc4afdb224c8f54695c8008a92de047fd8d4b5916ac79.png" src="../_images/4020385795cb3ce7ae1fc4afdb224c8f54695c8008a92de047fd8d4b5916ac79.png" />
</div>
</div>
</section>
<section id="simulation-based-calibration">
<h4><span class="section-number">1.6.3.2. </span>Simulation-Based Calibration <a class="anchor" id="simulation_based_calibration"></a><a class="headerlink" href="#simulation-based-calibration" title="Link to this heading">#</a></h4>
<p>By now a classic in Bayesian analysis. If you are not familiar with this procedure, you must read about it here: https://arxiv.org/abs/1804.06788</p>
<p>SBC is a technique used to assess whether a probabilistic model correctly infers parameters from data. The basic idea is to simulate a large number of datasets from the model’s prior distribution and then perform posterior inference on these simulated datasets. The goal is to check if the inferred posterior distributions are consistent with the priors. Essentially, SBC tests if the model can accurately recover the parameters it used to generate the data in the first place. This process helps identify any systematic biases or inaccuracies in the model’s inference process.</p>
<p>To perform SBC, we first need to obtain <code class="docutils literal notranslate"><span class="pre">L</span></code> number of posterior draws from <code class="docutils literal notranslate"><span class="pre">M</span></code> simulated data sets. While the procedure is typically intractable, amortized inference allows us to perform SBC instantly.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Obtain 100 posterior samples for each simulated data set in test_sims</span>
<span class="n">posterior_samples</span> <span class="o">=</span> <span class="n">amortizer</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">test_sims</span><span class="p">,</span> <span class="n">n_samples</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">f</span> <span class="o">=</span> <span class="n">bf</span><span class="o">.</span><span class="n">diagnostics</span><span class="o">.</span><span class="n">plot_sbc_histograms</span><span class="p">(</span><span class="n">posterior_samples</span><span class="p">,</span> <span class="n">test_sims</span><span class="p">[</span><span class="s2">&quot;parameters&quot;</span><span class="p">],</span> <span class="n">num_bins</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>INFO:root:The ratio of simulations / posterior draws should be &gt; 20 for reliable variance reduction, but your ratio is 5.                    Confidence intervals might be unreliable!
</pre></div>
</div>
<img alt="../_images/5e6a71275883e467811c6d17afb548b0c978e8705c08b414df9007b9cb28708a.png" src="../_images/5e6a71275883e467811c6d17afb548b0c978e8705c08b414df9007b9cb28708a.png" />
</div>
</div>
<p>Note, that the above function complains about the simulations-to-posterior-samples ratio, which is too low for reasonable density estimation and confidence intervals. Thus, we may want to use the more modern version of SBC which is based on empirical cumulative distribution functions (ECDFs) and does not have a <code class="docutils literal notranslate"><span class="pre">num_bins</span></code> hyperparameter. You can read more about this method at https://arxiv.org/abs/2103.10522.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">f</span> <span class="o">=</span> <span class="n">bf</span><span class="o">.</span><span class="n">diagnostics</span><span class="o">.</span><span class="n">plot_sbc_ecdf</span><span class="p">(</span><span class="n">posterior_samples</span><span class="p">,</span> <span class="n">test_sims</span><span class="p">[</span><span class="s2">&quot;parameters&quot;</span><span class="p">],</span> <span class="n">difference</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/3a054f368dba66b44bbfba9222cb94ea477d374cf97e2df2f81d194a8ae5699b.png" src="../_images/3a054f368dba66b44bbfba9222cb94ea477d374cf97e2df2f81d194a8ae5699b.png" />
</div>
</div>
</section>
<section id="posterior-z-score-and-contraction">
<h4><span class="section-number">1.6.3.3. </span>Posterior z-score and contraction <a class="anchor" id="posterior_z_score_and"></a><a class="headerlink" href="#posterior-z-score-and-contraction" title="Link to this heading">#</a></h4>
<ul class="simple">
<li><p>Posterior z-score: It measures how many standard deviations away the mean of the posterior distribution is from the true value of the parameter. A z-score of 0 indicates the mean perfectly aligns with the true value (no bias) while positive/negative z-scores indicate positive/negative bias, respectively.</p></li>
<li><p>Posterior contraction: It measures how much the posterior distribution contracts around the true value of the parameter as more data is observed. A higher contraction indicates that the data provides strong evidence, narrowing the uncertainty range.</p></li>
</ul>
<p>Ideally, we should obtain high contraction and a z-score near 0. This means the model accurately captures the true value with little bias and high confidence.</p>
<p>A quick and dirty way to gain an understanding of how good point estimates and uncertainty estimates capture the “true” parameters, assuming the generative model is well-specified. For this, we will draw more samples from the posteriors in order to get smaller Monte Carlo error.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">post_samples</span> <span class="o">=</span> <span class="n">amortizer</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">test_sims</span><span class="p">,</span> <span class="n">n_samples</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Note the shapes of our resulting array: <code class="docutils literal notranslate"><span class="pre">(500,</span> <span class="pre">1000,</span> <span class="pre">4)</span></code>. The resulting array holds the <span class="math notranslate nohighlight">\(1000\)</span> posterior draws (axis 1) for each of the <span class="math notranslate nohighlight">\(500\)</span> data sets (axis 0). The final axis (axis 2) represents the number of target parameters.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Shape of posterior samples array:&quot;</span><span class="p">,</span> <span class="n">post_samples</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Shape of posterior samples array: (500, 1000, 4)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">f</span> <span class="o">=</span> <span class="n">bf</span><span class="o">.</span><span class="n">diagnostics</span><span class="o">.</span><span class="n">plot_recovery</span><span class="p">(</span><span class="n">post_samples</span><span class="p">,</span> <span class="n">test_sims</span><span class="p">[</span><span class="s2">&quot;parameters&quot;</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/4981589dcae8acf9c7d9cda5438501db43f3c97ebc902694d60c86f918744bb3.png" src="../_images/4981589dcae8acf9c7d9cda5438501db43f3c97ebc902694d60c86f918744bb3.png" />
</div>
</div>
<p>Even better, you might want to inspect the sensitivity of the model in terms of how good some expectation (e.g., the mean) captures the ground truth parameter and how much the posterior shrinks with regard to the prior (i.e., so called posterior contraction). For that, we can compute the prior variance analytically or simply estimate it via Monte Carlo.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">f</span> <span class="o">=</span> <span class="n">bf</span><span class="o">.</span><span class="n">diagnostics</span><span class="o">.</span><span class="n">plot_z_score_contraction</span><span class="p">(</span><span class="n">post_samples</span><span class="p">,</span> <span class="n">test_sims</span><span class="p">[</span><span class="s2">&quot;parameters&quot;</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/fd093cb6f243a7e185a4851302453ff030255ff6ea8947378239902abf6bb62a.png" src="../_images/fd093cb6f243a7e185a4851302453ff030255ff6ea8947378239902abf6bb62a.png" />
</div>
</div>
<p>We observe the best case of model adequacy - no bias and large contraction. You can play around with different samples sizes per simulation (i.e., the <code class="docutils literal notranslate"><span class="pre">n_obs</span></code> argument in the likelihood function) and check all diagnostics again. Or, even better, you can try estimating your own models!</p>
</section>
</section>
</section>
<section id="inference-phase">
<h2><span class="section-number">1.7. </span>Inference Phase <a class="anchor" id="inference_phase"></a><a class="headerlink" href="#inference-phase" title="Link to this heading">#</a></h2>
<p>Once the approximator has passed all consistency checks, we can now go ahead and apply it to real data! Since the data-generating parameters of real systems are per definition unobservable, we cannot use the same methods as below for ascertaining real-world validity of our inferences. Hence, as in any modeling scenario, we would need external validation and posterior predictive checks.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Your code here</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>


                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="../examples.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Examples</p>
      </div>
    </a>
    <a class="right-next"
       href="TwoMoons_Bimodal_Posterior.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">2. </span>Two Moons: Tackling Bimodal Posteriors</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <dialog id="pst-secondary-sidebar-modal"></dialog>
                <div id="pst-secondary-sidebar" class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#table-of-contents">1.1. Table of Contents</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#introduction">1.2. Introduction <a class="anchor" id="introduction"></a></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#defining-the-generative-model">1.3. Defining the Generative Model <a class="anchor" id="defining_the_generative"></a></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#prior">1.3.1. Prior <a class="anchor" id="prior"></a></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#simulator">1.3.2. Simulator <a class="anchor" id="simulator"></a></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#generative-model">1.3.3. Generative Model <a class="anchor" id="generative_model"></a></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#defining-the-neural-approximator">1.4. Defining the Neural Approximator <a class="anchor" id="defining_the_neural"></a></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#summary-network">1.4.1. Summary Network <a class="anchor" id="summary_network"></a></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#inference-network">1.4.2. Inference Network <a class="anchor" id="inference_network"></a></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#amortized-posterior">1.4.3. Amortized Posterior <a class="anchor" id="amortized_posterior"></a></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#defining-the-trainer">1.5. Defining the Trainer <a class="anchor" id="defining_the_trainer"></a></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#training-phase">1.6. Training Phase <a class="anchor" id="training_phase"></a></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#online-training">1.6.1. Online Training <a class="anchor" id="online_training"></a></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#inspecting-the-loss">1.6.2. Inspecting the Loss <a class="anchor" id="inspecting_the_loss"></a></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#validating-consistency">1.6.3. Validating Consistency <a class="anchor" id="validating_consistency"></a></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#latent-space-inspection">1.6.3.1. Latent space inspection <a class="anchor" id="latent_space_inspection"></a></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#simulation-based-calibration">1.6.3.2. Simulation-Based Calibration <a class="anchor" id="simulation_based_calibration"></a></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#posterior-z-score-and-contraction">1.6.3.3. Posterior z-score and contraction <a class="anchor" id="posterior_z_score_and"></a></a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#inference-phase">1.7. Inference Phase <a class="anchor" id="inference_phase"></a></a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By The BayesFlow authors
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2023, BayesFlow authors (lead maintainer: Stefan T. Radev).
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script defer src="../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf"></script>
<script defer src="../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>